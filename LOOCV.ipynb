{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import statistics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, LeaveOneOut, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, WhiteKernel, RationalQuadratic, Matern\n",
    "from sklearn import preprocessing \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Three functions that are necessary to convert lists into strings and vice versa. For example,\n",
    "converting the list [1,2,3] to the string \"[1,2,3]\". This is necessary in order to legibly store long\n",
    "vectors in a .csv final using the Pandas module. \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def str2float(string):\n",
    "    split = list(string.split(','))\n",
    "    floats_split = []\n",
    "    for i in range(len(split)):\n",
    "        floats = float(split[i])\n",
    "        floats_split.append(floats)\n",
    "    return floats_split\n",
    "\n",
    "def stringToList(vectors):\n",
    "    bracket_removed_mol2vec = []\n",
    "    for i in range(len(vectors)):\n",
    "        new_strings = vectors[i].replace('[', '')\n",
    "        newer_strings = new_strings.replace(']', '')\n",
    "        bracket_removed_mol2vec.append(newer_strings)\n",
    "\n",
    "    xList = []\n",
    "    for i in range(len(bracket_removed_mol2vec)):\n",
    "        float_vec = str2float(bracket_removed_mol2vec[i])\n",
    "        xList.append(float_vec)\n",
    "    \n",
    "    return xList\n",
    "\n",
    "def listToString(vectors):\n",
    "    string_indices = []\n",
    "    for i in range(len(vectors)):\n",
    "        knn_string = ', '.join(str(k) for k in vectors[i])\n",
    "        string_indices.append(knn_string)\n",
    "\n",
    "    bracket_string_indices = []\n",
    "    for i in range(len(string_indices)):\n",
    "        bracket_string = '[' + string_indices[i] + ']'\n",
    "        bracket_string_indices.append(bracket_string)\n",
    "    \n",
    "    return bracket_string_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Uploads information about detected species\n",
    "\n",
    "Inputs: None\n",
    "Outputs: List of feature vectors, log 10 column densities, column densities and SMILES strings\n",
    "of each detected molecule\n",
    "'''\n",
    "\n",
    "def uploadIso():\n",
    "    fullPath = os.path.join(os.getcwd(), 'detectionDataset.csv')\n",
    "    fullUpload = pd.read_csv(fullPath)\n",
    "\n",
    "\n",
    "    # Extract mol2vec\n",
    "    exactList = list(fullUpload['Exact'])\n",
    "    smileList = list(fullUpload['smiles'])\n",
    "    idxList = []\n",
    "    for i in range(len(exactList)):\n",
    "        if exactList[i] == \"Y\":\n",
    "            idxList.append(i)\n",
    "            \n",
    "                     \n",
    "    newDataset = fullUpload.iloc[idxList]\n",
    "    mol2vec_strings = list(newDataset['mol2vecIsoSameNew'])\n",
    "    detectedSmiles = list(newDataset['smiles'])\n",
    "    \n",
    "    xList = stringToLisT(mol2vec_strings)\n",
    "    \n",
    "    cd = newDataset['N'].tolist()\n",
    "    \n",
    "    cdLog = np.array(np.log10(cd))\n",
    "    \n",
    "    return xList, cdLog, cd, detectedSmiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Uploads information about detected species (including whether their column denisty should be predicted)\n",
    "\n",
    "Inputs: None\n",
    "Outputs: List of feature vectors, log 10 column densities, column densities and SMILES strings\n",
    "of each detected molecule and a list contianing information on whether the column density for a molecule should\n",
    "be predicted\n",
    "'''\n",
    "\n",
    "\n",
    "def uploadIsoVal():\n",
    "    fullPath = os.path.join(os.getcwd(), 'all_files/Updated_Smiles/detectionDataset.csv')\n",
    "    fullUpload = pd.read_csv(fullPath)\n",
    "\n",
    "\n",
    "    # Extract mol2vec\n",
    "    exactList = list(fullUpload['Exact'])\n",
    "    smileList = list(fullUpload['smiles'])\n",
    "    idxList = []\n",
    "    for i in range(len(exactList)):\n",
    "        if exactList[i] == \"Y\":\n",
    "            idxList.append(i)\n",
    "                     \n",
    "    newDataset = fullUpload.iloc[idxList]\n",
    "    mol2vec_strings = list(newDataset['mol2vec'])\n",
    "    detectedSmiles = list(newDataset['smiles'])\n",
    "    predictList = list(newDataset['Predict'])\n",
    "    cd = list(newDataset['N'])\n",
    "    \n",
    "    cdLog = np.array(np.log10(cd))\n",
    "    \n",
    "    return xList, cdLog, cd, detectedSmiles, predictList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aff032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''\n",
    "Removes a single feature vector and corresponding column density for LOOCV\n",
    "\n",
    "Inputs: Total list of vectors, total list of column densities and index to be removed\n",
    "Returns: Resulting complete vector and column density lists with one removed from each,\n",
    "the feature vector and column density that were removed for cross validation\n",
    "\n",
    "'''\n",
    "def removeValidation(vectorList, cdList, idx):\n",
    "    valVectorList = []\n",
    "    valCdList = []\n",
    "    valVector = vectorList.pop(idx)\n",
    "    cdList = list(cdList)\n",
    "    valCd = cdList.pop(idx)\n",
    "    valVectorList.append(valVector)\n",
    "    valCdList.append(valCd)\n",
    "    valVectorList = np.array(valVectorList)\n",
    "    valCdList = np.array(valCdList)\n",
    "    \n",
    "    return vectorList, cdList, valVectorList, valCdList\n",
    "\n",
    "\n",
    "'''\n",
    "Sort and return an array of tuples by their second value\n",
    "'''\n",
    "def sortTupleArray(tup):\n",
    "    tup.sort(key = lambda x: x[1])\n",
    "    return tup\n",
    "\n",
    "\n",
    "'''\n",
    "Standardizes feature vectors so tha the individual features more\n",
    "or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "Input: Not yet scaled train and validation feature vectors\n",
    "Returns: Scaled train and validation feature vectors\n",
    "'''\n",
    "def scaleDataVal(X_train,X_val):\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train) #creating Standard Scaler Object \n",
    "    X_train_scaled = scaler.transform(X_train) #Scaling X_train\n",
    "    #X_tot_scaled = scaler.transform(X_tot)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    return X_train_scaled, X_val_scaled\n",
    "\n",
    "\n",
    "'''\n",
    "Bootstraps the training data to 800 samples and scales the dataset\n",
    "\n",
    "Input: Feature vectors and column densities in the training set as well as the feature vector used for \n",
    "cross validation\n",
    "\n",
    "Returns: Bootstrapped feature vectors and column densities in the training set as well as\n",
    "the scaled feature vector used for cross validation\n",
    "'''\n",
    "def splitBootScaleVal(x,y, xVal, bootSize = 800):\n",
    "\n",
    "    bootTrainSize = bootSize\n",
    "    X_train_boot, y_train_boot = resampling(x, y, bootTrainSize, 0.5)\n",
    "    X_train_bootScaled, X_val_scaled = scaleDataVal(X_train_boot,xVal)\n",
    "    return X_train_bootScaled, y_train_boot, X_val_scaled\n",
    "\n",
    "\n",
    "'''\n",
    "Training the model and predicting on the left-out sample using Gaussian process regression\n",
    "\n",
    "Inputs: bootstrapped feature vectors and column densities in the training set as well as \n",
    "the left-out feature vector and corresponding column density for cross validation\n",
    "\n",
    "Returns: The prediction error, column density prediction and prediction uncertainty (standard deviation)\n",
    "for the left-out molecule\n",
    "'''\n",
    "def runGPRVal(X_train_boot, y_train_boot, X_val, y_val): \n",
    "\n",
    "    kernel = RBF(length_scale=7) + WhiteKernel(noise_level=0.3, noise_level_bounds = (1e-10,1e5)) + DotProduct(sigma_0=0.001, sigma_0_bounds = (1e-10,1e5))\n",
    "    model = GaussianProcessRegressor(alpha=1e-10, kernel=kernel,normalize_y=True, random_state=55, n_restarts_optimizer= 20)\n",
    "\n",
    "    result = model.fit(X_train_boot, y_train_boot)\n",
    "    train_pred = result.predict(X_train_boot)\n",
    "    train_error = mean_squared_error(y_train_boot, train_pred)\n",
    "    validationResults, valSD = result.predict(X_val, return_std = True)\n",
    "    residualList = []\n",
    "    for i in range(len(validationResults)):\n",
    "        residual = validationResults[i] - y_val[i]\n",
    "        print(X_val[i][0])\n",
    "        print(\"Reported CD\")\n",
    "        print(y_val[i])\n",
    "        print(\"Predicted CD\")\n",
    "        print(validationResults[i])\n",
    "        print(\"residual\")\n",
    "        print(residual)\n",
    "        print(\"Standard Deviation\")\n",
    "        print(valSD[i])\n",
    "        sd = valSD[i]\n",
    "        validationResult = validationResults[i]\n",
    "    \n",
    "    return residual, validationResult, sd\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Training the model and predicting on the left-out sample using Bayesian Ridge Regression\n",
    "\n",
    "Inputs: bootstrapped feature vectors and column densities in the training set as well as \n",
    "the left-out feature vector and corresponding column density for cross validation\n",
    "\n",
    "Returns: The prediction error, column density prediction and prediction uncertainty (standard deviation)\n",
    "for the left-out molecule\n",
    "'''\n",
    "def runBRVal(X_train_boot, y_train_boot, X_val, y_val): \n",
    "\n",
    "    \n",
    "    model = BayesianRidge()\n",
    "\n",
    "    result = model.fit(X_train_boot, y_train_boot)\n",
    "    train_pred = result.predict(X_train_boot)\n",
    "    train_error = mean_squared_error(y_train_boot, train_pred)\n",
    "    validationResults, valSD = result.predict(X_val, return_std = True)\n",
    "    residualList = []\n",
    "    for i in range(len(validationResults)):\n",
    "        residual = validationResults[i] - y_val[i]\n",
    "        print(X_val[i][0])\n",
    "        print(\"Reported CD\")\n",
    "        print(y_val[i])\n",
    "        print(\"Predicted CD\")\n",
    "        print(validationResults[i])\n",
    "        print(\"residual\")\n",
    "        print(residual)\n",
    "        print(\"Standard Deviation\")\n",
    "        print(valSD[i])\n",
    "        sd = valSD[i]\n",
    "        validationResult = validationResults[i]\n",
    "    \n",
    "    return residual, validationResult, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1006e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "'''\n",
    "Loops through all of the molecules in the dataset of detections and predicts their column density through \n",
    "leave-one-out cross-validation with a Gaussian process regression. \n",
    "\n",
    "Inputs: None\n",
    "Outputs: A list of 4-tuples containing information about each column density prediction. \n",
    "The 4-tuples have the following format:\n",
    "\n",
    "(SMILES string, column density prediction error, column density prediction, 1 sigma prediction uncertainty)\n",
    "'''\n",
    "\n",
    "def runValidationGPR():\n",
    "    totalResidualList = []\n",
    "    residualNumList = []\n",
    "    xAll,yAll, yNonLog, smileList, predictList = uploadIsoVal()\n",
    "\n",
    "    #print(len(xAll))\n",
    "    #print(len(xAll[0]))\n",
    "    \n",
    "    #idx = smileList.index(\"[2H]OCC=O\")\n",
    "    #idxList = [idx]\n",
    "    #for i in idxList:\n",
    "    for i in range(len(smileList)):\n",
    "        #if predictList[i] != \"N (u)\" and predictList[i] != \"Y\":\n",
    "        print(\"iteration\" + \" \" + str(i+1))\n",
    "        print(smileList[i])\n",
    "        xTot, yTot, yUnprocessed, smiles = uploadIso()\n",
    "        #print(\"xTot\")\n",
    "        #print(len(xTot[0]))\n",
    "        xSet, ySet, xVal, y_val = removeValidation(xTot,yTot,i)\n",
    "        ySet = np.array(ySet)\n",
    "        X_train, y_train, X_val = splitBootScaleVal(xSet, ySet, xVal)\n",
    "        #print(len(X_train[0]))\n",
    "        #print(\"X_test\")\n",
    "        #print(len(X_val))\n",
    "        residualList, validationResult, sd = runGPRVal(X_train,y_train, X_val, y_val)\n",
    "        totalResidualList.append((smileList[i],abs(residualList),validationResult,sd))\n",
    "        residualNumList.append(abs(residualList))\n",
    "        print(\"--------\")\n",
    "\n",
    "\n",
    "    print(len(totalResidualList))\n",
    "    totalResidualList = sortTupleArray(totalResidualList)\n",
    "    print(totalResidualList)\n",
    "    print(\"AVERAGE RESIDUAL\")\n",
    "    averageResidual = sum(residualNumList) / len(residualNumList)\n",
    "    residualNumList.sort()\n",
    "    print(averageResidual)\n",
    "    print(\"MEDIAN RESIDUAL\")\n",
    "    print(statistics.median(residualNumList))\n",
    "\n",
    "    return totalResidualList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d28e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "'''\n",
    "Loops through all of the molecules in the dataset of detections and predicts their column density through \n",
    "leave-one-out cross-validation with a Bayesian ridge regression. \n",
    "\n",
    "Inputs: None\n",
    "Outputs: A list of 4-tuples containing information about each column density prediction. \n",
    "The 4-tuples have the following format:\n",
    "\n",
    "(SMILES string, column density prediction error, column density prediction, 1 sigma prediction uncertainty)\n",
    "'''\n",
    "\n",
    "def runValidationBR():\n",
    "    totalResidualList = []\n",
    "    residualNumList = []\n",
    "    xAll,yAll, yNonLog, smileList, predictList = uploadIsoVal()\n",
    "\n",
    "    #print(len(xAll))\n",
    "    #print(len(xAll[0]))\n",
    "    \n",
    "    #idx = smileList.index(\"[2H]OCC=O\")\n",
    "    #idxList = [idx]\n",
    "    #for i in idxList:\n",
    "    for i in range(len(smileList)):\n",
    "        #if predictList[i] != \"N (u)\" and predictList[i] != \"Y\":\n",
    "        print(\"iteration\" + \" \" + str(i+1))\n",
    "        print(smileList[i])\n",
    "        xTot, yTot, yUnprocessed, smiles = uploadIso()\n",
    "        #print(\"xTot\")\n",
    "        #print(len(xTot[0]))\n",
    "        xSet, ySet, xVal, y_val = removeValidation(xTot,yTot,i)\n",
    "        ySet = np.array(ySet)\n",
    "        X_train, y_train, X_val = splitBootScaleVal(xSet, ySet, xVal)\n",
    "        #print(len(X_train[0]))\n",
    "        #print(\"X_test\")\n",
    "        #print(len(X_val))\n",
    "        residualList, validationResult, sd = runBRVal(X_train,y_train, X_val, y_val)\n",
    "        totalResidualList.append((smileList[i],abs(residualList),validationResult,sd))\n",
    "        residualNumList.append(abs(residualList))\n",
    "        print(\"--------\")\n",
    "\n",
    "\n",
    "    print(len(totalResidualList))\n",
    "    totalResidualList = sortTupleArray(totalResidualList)\n",
    "    print(totalResidualList)\n",
    "    print(\"AVERAGE RESIDUAL\")\n",
    "    averageResidual = sum(residualNumList) / len(residualNumList)\n",
    "    residualNumList.sort()\n",
    "    print(averageResidual)\n",
    "    print(\"MEDIAN RESIDUAL\")\n",
    "    print(statistics.median(residualNumList))\n",
    "\n",
    "    return totalResidualList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
